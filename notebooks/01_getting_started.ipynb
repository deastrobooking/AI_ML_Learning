{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05da2faa",
   "metadata": {},
   "source": [
    "# Getting Started with AI/ML Training\n",
    "\n",
    "This notebook demonstrates how to use the AI_ML_Learning repository for training models.\n",
    "\n",
    "## Contents\n",
    "1. Environment Setup\n",
    "2. Data Loading\n",
    "3. Model Creation\n",
    "4. Training\n",
    "5. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7beb459d",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e8c7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from src.models import SimpleCNN, get_model\n",
    "from src.training import Trainer, get_optimizer, get_scheduler\n",
    "from src.data_utils import get_image_transforms, create_data_loaders\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda if torch.cuda.is_available() else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11bb25d",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "Let's load a sample dataset (MNIST for demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6389c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and prepare MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    '../data/raw',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "val_dataset = datasets.MNIST(\n",
    "    '../data/raw',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b75662",
   "metadata": {},
   "source": [
    "### Visualize some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91414454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    image, label = train_dataset[i]\n",
    "    ax.imshow(image.squeeze(), cmap='gray')\n",
    "    ax.set_title(f'Label: {label}')\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0fb574",
   "metadata": {},
   "source": [
    "### Create data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7016695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "print(f\"Number of training batches: {len(train_loader)}\")\n",
    "print(f\"Number of validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409cd90a",
   "metadata": {},
   "source": [
    "## 3. Model Creation\n",
    "\n",
    "Create a simple CNN for MNIST classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e7f1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create model\n",
    "model = SimpleCNN(num_classes=10, input_channels=1)\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nModel Architecture:\")\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe1ffdb",
   "metadata": {},
   "source": [
    "## 4. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24806387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = get_optimizer(model, 'adam', lr=0.001)\n",
    "scheduler = get_scheduler(optimizer, 'reduce_on_plateau', patience=3, factor=0.5)\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    scheduler=scheduler,\n",
    "    save_dir='../models/checkpoints',\n",
    "    experiment_name='mnist_cnn'\n",
    ")\n",
    "\n",
    "print(\"Trainer initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f023910",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0c14a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for 5 epochs\n",
    "history = trainer.fit(num_epochs=5, early_stopping_patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea16091",
   "metadata": {},
   "source": [
    "## 5. Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61452ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss curves\n",
    "ax1.plot(history['train_losses'], label='Train Loss', marker='o')\n",
    "ax1.plot(history['val_losses'], label='Val Loss', marker='s')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Accuracy curves\n",
    "ax2.plot(history['train_accuracies'], label='Train Accuracy', marker='o')\n",
    "ax2.plot(history['val_accuracies'], label='Val Accuracy', marker='s')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('Training and Validation Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nBest Validation Loss: {min(history['val_losses']):.4f}\")\n",
    "print(f\"Best Validation Accuracy: {max(history['val_accuracies']):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b483af",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation\n",
    "\n",
    "Test the model on some sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e597717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "model.eval()\n",
    "\n",
    "# Get a batch of test images\n",
    "test_images, test_labels = next(iter(val_loader))\n",
    "test_images = test_images.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(test_images)\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "# Visualize predictions\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    image = test_images[i].cpu().squeeze()\n",
    "    pred = predictions[i].cpu().item()\n",
    "    true = test_labels[i].item()\n",
    "    \n",
    "    ax.imshow(image, cmap='gray')\n",
    "    color = 'green' if pred == true else 'red'\n",
    "    ax.set_title(f'Pred: {pred}, True: {true}', color=color)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e63ed7",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Try different model architectures (ResNet, custom models)\n",
    "2. Experiment with hyperparameters\n",
    "3. Add data augmentation\n",
    "4. Implement early stopping\n",
    "5. Use TensorBoard or Weights & Biases for experiment tracking\n",
    "6. Try transfer learning with pretrained models"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
